<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Emerging Challenges &mdash; DASH Tetra Project Knowledge Base 1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=91e4a3f0"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Dataset Anonymization" href="dataset_anonymization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DASH Tetra Project Knowledge Base
          </a>
              <div class="version">
                1.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../context.html">Context of this documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Federated Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../fl/basic-concepts.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/frameworks.html">Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/methodology.html">Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/applications.html">Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/sme-implementation-strategies.html">SME Implementation Strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/case-studies-for-smes.html">Case Studies for SMEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/technical-challenges-and-solutions.html">Technical Challenges and Solutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/privacy-and-security-considerations-for-smes.html">Privacy and Security Considerations for SMEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fl/tools-and-resources-for-smes.html">Tools and Resources for SMEs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Privacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy.html">Differential Privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_anonymization.html">Dataset Anonymization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Emerging Challenges</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DASH Tetra Project Knowledge Base</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Emerging Challenges</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/topics/data-privacy/emerging_challenges.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="emerging-challenges">
<h1>Emerging Challenges<a class="headerlink" href="#emerging-challenges" title="Permalink to this heading"></a></h1>
<p>The aforementioned dataset anonymization techniques can offer an appropriate level of privacy towards individuals in the data set. It is also clear that data set anonymization is superior with respect to privacy compared to pseudonymization. Moreover, metrics quantify the privacy level achieved in a transformed data set. However, many challenges remain. Some of them are discussed below.</p>
<p>First, multiple attacks can still be performed on anonymized data sets. A straightforward one is to enrich anonymized data with publicly available data (like data that is exposed on social networks). Doing so sometimes allows to re-identify certain individuals in an anonymized data set, or map records to individuals with a very high probability. Similarly, service providers can release another transformed version of the same original data set to different data processors. Although each transformed data set separately is not vulnerable to re-identification attacks, colluding data processors can do so by combining their view on the data set in some scenarios.</p>
<p>Second, applying solid generalizations can offer an appropriate level of privacy protection. However, doing so can undermine the utility of the transformed data set with respect to machine learning or optimization purposes. Data processors are no longer interested in useless transformed data. Therefore, privacy and utility must be balanced when applying data sets transformations. Note that – like anonymity metrics – metrics exist to quantify the utility level of transformed datasets. Examples are discernability, ambiguity and classification metrics. However, practical experiments have shown that the widely recognized theoretic utility metrics often do not reflect the real value of the transformed dataset for a concrete purpose.</p>
<p>Third, the original sensitive data is often outsourced either (a) to external cloud providers that store and/or process the sensitive data on demand of the data owners, or (b) to software developers that need representative data to test their software that is built on demand of the data owners. Multiple techniques exist to protect the data towards honest-yet-curious service providers. For instance, data can be encrypted before it is sent to cloud providers. Homomorphic encryption schemes even allow service providers to execute algorithms on encrypted data. This typically comes with a serious performance penalty. Moreover, the data processing purpose must already be known in advance, which seriously impacts its flexibility. To meet the testing demands of external software developers, synthetic data can be provided. This allows to test software and scripts without privacy risks. Similarly, format-preserving encryption schemes avoid identifying data in test environments, thereby preserving the structure and format of the original data.</p>
<p>Finally, generating and releasing artificial data with similar statistical properties as the ones in the original data set is often proposed as an alternative to applying traditional anonymization techniques. Moreover, it is often argued that re-identification is no longer possible as the data is artificial. However, artificial data is often generated by a machine learning algorithm that is trained with the original data set, or a large subset. It is widely known and proven that machine learning algorithms often leak information about the training data. This means that re-identification attacks can be performed. Those attacks typically become more effective if more artificial data is released to an attacker. Moreover, it is no longer possible to apply the intuitive anonymity metrics – like k-anonymity – that can be applied to data sets that are transformed with traditional generalization strategies. This can seriously complicate the assessment of the (artificial) data set with respect to anonymity.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dataset_anonymization.html" class="btn btn-neutral float-left" title="Dataset Anonymization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>